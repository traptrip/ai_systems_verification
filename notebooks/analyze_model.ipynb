{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from scripts.model import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "dummy_model = create_model(1e-3)\n",
    "dummy_model.build((None, 28, 28))\n",
    "model_from_ckpt = tf.keras.saving.load_model(\"../checkpoint/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model from checkpoint\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 16)                12560     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12730 (49.73 KB)\n",
      "Trainable params: 12730 (49.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Model from training file\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                12560     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12730 (49.73 KB)\n",
      "Trainable params: 12730 (49.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Model from checkpoint\")\n",
    "model_from_ckpt.summary()\n",
    "\n",
    "print(\"\\nModel from training file\")\n",
    "dummy_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[0.1052354  0.12885886 0.05414566 0.08328817 0.07449424 0.18258691\n",
      "  0.10668295 0.16862217 0.03097621 0.06510942]]\n"
     ]
    }
   ],
   "source": [
    "dummy_input = np.zeros((1, 28, 28))\n",
    "print(dummy_model.predict(dummy_input))\n",
    "print(model_from_ckpt.predict(dummy_input.reshape(1, 784)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../data/mnist_test.csv\")\n",
    "x = test.iloc[:, 1:].values / 255.0\n",
    "y = test.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 449us/step\n"
     ]
    }
   ],
   "source": [
    "preds = model_from_ckpt.predict(x)\n",
    "preds = preds.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.94      0.92      0.93      1032\n",
      "           3       0.94      0.92      0.93      1010\n",
      "           4       0.94      0.93      0.94       982\n",
      "           5       0.93      0.91      0.92       892\n",
      "           6       0.94      0.96      0.95       958\n",
      "           7       0.94      0.93      0.94      1028\n",
      "           8       0.92      0.91      0.91       974\n",
      "           9       0.91      0.93      0.92      1009\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y, preds)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "\n",
    "1. Архитектура модели в файле обучения не соответствует той, которая предоставленна в виде чекпоинта в папке 'v1/'\n",
    "2. Нет фиксации seed во время обучения\n",
    "3. Нет сохранения результатов валидации, что затрудняет оценку модели, при передаче ее другим разработчикам\n",
    "\n",
    "\n",
    "Модель чекпоинта состоит из 3 слоев: 2 линейных слоя между которыми стоит dropout слой. Также после 1 линейного слоя применяется активация ReLU, для того, чтобы внести нелинейность в модель. После второго линейного слоя применяется активация Softmax приводящая выходы модели к виду где i-й элемент результирующего массива является вероятностью того, что i-й класс является ответом. \n",
    "На вход модель принимает изображение приведенное к формату (batch_size, 28x28). На выход выдает массив размера (batch_size, num_classes), так как для обучения используется датасет MNIST, то num_classes = 10 -- кол-во цифр. \n",
    "\n",
    "Dense реализует операцию: output = activation(dot(input, kernel) + bias), где активация — это функция активации по элементам, переданная в качестве аргумента активации, кернел — это матрица весов, созданная слоем, а смещение — это вектор смещения, созданный слоем (применимо только в случае, если use_bias — True).\n",
    "\n",
    "Слой Dropout состоит в случайной установке доли единиц ввода в 0 при каждом обновлении во время обучения, что помогает предотвратить переобучение (оверфиттинг). В даннос случае значение rate=0.1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
